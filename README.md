# PDF Reader

This full-stack application enables users to upload PDF files and interact with an AI chatbot to ask questions about the content. The app consists of a **React frontend** and a **FastAPI backend**, utilizing a large language model (LLM) from Hugging Face for responses.

---

## Table of Contents

- [Project Structure](#project-structure)
- [Frontend Setup](#frontend-setup)
- [Backend Setup](#backend-setup)
- [Deployed Version](#deployed-version)
- [Usage](#usage)
- [Notes](#notes)

---

## Project Structure

- **`frontend/`**: Contains the React frontend code.
  - Run with `npm start`.
  - Manages UI, file uploads, and chat interface.

- **`backend/`**: Contains the FastAPI backend code.
  - Run with `uvicorn main:app --reload`.
  - Processes PDF uploads and handles AI query responses.

---

## Frontend Setup

1. **Navigate to the Frontend Directory**:
   ```bash
   cd frontend
   ```

2. **Install Dependencies**:
   ```bash
   npm install
   ```

3. **Start the Frontend Server**:
   ```bash
   npm start
   ```

4. **Configure API URL**:
   - Open `Api.js` in the `frontend` folder.
   - Specify the backend server URL and port where the FastAPI server is running.

---

## Backend Setup

1. **Create and Activate Virtual Environment**:
   - Create a virtual environment to manage dependencies:
     ```bash
     python -m venv your_env_name
     ```
   - Activate the environment:
     ```bash
     # On Windows
     your_env_name\Scripts\activate

     # On macOS/Linux
     source your_env_name/bin/activate
     ```

2. **Install Dependencies**:
   - Navigate to the backend folder and install all necessary packages:
     ```bash
     cd backend
     pip install -r requirements.txt
     ```

3. **Setup Hugging Face Access Token**:
   - Ensure you have a Hugging Face account.
   - Set up an access token in your account and add it to the environment:
     ```bash
     export HUGGINGFACEHUB_API_TOKEN="your_huggingface_api_token"
     ```

4. **Run the Backend Server**:
   - Start the FastAPI backend server:
     ```bash
     uvicorn main:app --reload
     ```

---

## Deployed Version

For the deployed version, use the following URLs:

- **Backend Server**: [https://pdf-reader-zunu.onrender.com/](https://pdf-reader-zunu.onrender.com/)  
  - *Note*: It may take a few seconds for the backend server to load.

- **Frontend Server**: [https://pdf-reader-nu.vercel.app/](https://pdf-reader-nu.vercel.app/)  
  - This server generally loads faster.

---

## Usage

1. **Open the Deployed Frontend** or **Run the App Locally** (following setup instructions above).
2. Click on the `+` button to upload a PDF file.
3. After selecting a file, click on **Upload PDF** to send the document to the server.
4. In the chatbox, type a question related to the uploaded PDF content and press **Send**.
5. Wait a few seconds (2-5) for a response generated by the AI model based on the PDF content.

---

## Notes

- Ensure that the backend server is running and accessible to the frontend.
- Adjust CORS settings during development to allow frontend-backend communication.
- A **Hugging Face access token** is required for backend interaction with the LLM model.
```
